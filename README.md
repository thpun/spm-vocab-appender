# spm-vocab-appender
Utility scripts to append vocabulary to pretrained SentencePiece model

This repo includes 3 scripts:
* [unk-explorer.py](#unk-explorer.py): Analyze moses-format corpus and look for unknown tokens
* [vocab-appender.py](#vocab-appender.py): Append vocabulary to pretrained SentencePiece model
* [mbart-add-tokens.py](#mbart-add-tokens.py): Modify pretrained mBART model to incorporate new vocabulary in dictionary

sentencepiece_model_pb2.py is generated by protocol buffers compiler:
```bash
git clone https://github.com/google/sentencepiece
cd sentencepiece/src/
protoc --python_out=. sentencepiece_model.proto
```

## unk-explorer.py
Analyze moses-format corpus and look for unknown tokens.
Output file is in TSV format: unknown token (1st col), occurrence (2nd col)

```bash
$ python unk-explorer.py --help
usage: unk-explorer.py [-h] [-m MODEL] [-i INPUT] [-o OUTPUT]

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        path to sentencepiece model to use
  -i INPUT, --input INPUT
                        path to input file. Default: stdin
  -o OUTPUT, --output OUTPUT
                        path to output file. Default: stdout
```

Example:
```bash
$ python unk-explorer.py -m mbart.cc25/sentence.bpe.model -i train.zh -o unknown-tokens.tsv
```

## vocab-appender.py
Append vocabulary to pretrained SentencePiece model and save the new model.
Input file should be a list of vocabulary to be added, one for each line.

```bash
$ python vocab-appender.py --help
usage: vocab-appender.py [-h] [-m MODEL] -i INPUT -o OUTPUT

Append unknown vocabulary to pretrained sentencepiece model

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        path to existing sentencepiece model to use
  -i INPUT, --input INPUT
                        path to input unknown vocabulary file
  -o OUTPUT, --output OUTPUT
                        path to new sentencepiece model
```

Example:
```bash
$ python vocab-appender.py -m mbart.cc25/sentence.bpe.model -i tokens-tba.txt -o new.model
```

## mbart-add-tokens.py
Modify pretrained mBART model to incorporate new vocabulary in dictionary such that the model size matches the dictionary size

```bash
$ python mbart-add-tokens.py --help
usage: mbart-add-tokens.py [-h] --offset N -n N -i INPUT -o OUTPUT

Extend embedding size of pretrained mBART model

optional arguments:
  -h, --help            show this help message and exit
  --offset N            size of dictionary to offset, i.e. the start position
                        to insert new tokens
  -n N, --number N      number of tokens to insert
  -i INPUT, --input INPUT
                        path to input checkpoint
  -o OUTPUT, --output OUTPUT
                        path to output checkpoint
```

Example:
```bash
$ python mbart-add-tokens.py --offset 249997 -n $(tokens-tba.txt | wc -l) -i mbart.cc25/model.pt -o new-model.pt
```
